import os
import io
import cv2
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
from PIL import Image, ImageEnhance, ImageOps, ImageFilter

# --- Ayarlar ---
MUSIQ_MODEL_URL = 'https://tfhub.dev/google/musiq/ava/1'
TEST_IMAGE_PATH = 'rido.jpg'  # Analiz edilecek gÃ¶rsel
MODEL_REQUIRED_SIZE = (224, 224)


# --- "AÅÃ‡ININ TARÄ°F DEFTERÄ°" (TÃ¼m Tarifler) ---

def recipe_recover_highlights(pil_image):
    """TARÄ°F 1: "AÅŸÄ±rÄ± Pozlama" sorununu katmanlama tekniÄŸiyle Ã§Ã¶zer."""
    print("     -> Tarif uygulanÄ±yor: PatlamÄ±ÅŸ AlanlarÄ± Kurtarma...")
    # ... (kod aynÄ±)
    cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    factor = 0.80
    corrected_pil = ImageEnhance.Brightness(pil_image).enhance(factor)
    corrected_pil = ImageEnhance.Contrast(corrected_pil).enhance(1.1)
    corrected_cv = cv2.cvtColor(np.array(corrected_pil), cv2.COLOR_RGB2BGR)
    gray_original = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
    _, mask = cv2.threshold(gray_original, 200, 255, cv2.THRESH_BINARY)
    mask_float = mask.astype(np.float32) / 255.0
    mask_3ch = cv2.merge([mask_float, mask_float, mask_float])
    img1 = cv_image.astype(np.float32)
    img2 = corrected_cv.astype(np.float32)
    blended_float = img1 * (1.0 - mask_3ch) + img2 * mask_3ch
    final_cv_image = np.uint8(np.clip(blended_float, 0, 255))
    return Image.fromarray(cv2.cvtColor(final_cv_image, cv2.COLOR_BGR2RGB))


def recipe_clahe_contrast_enhancement(pil_image):
    """TARÄ°F 2 (SAYISAL): DÃ¼ÅŸÃ¼k kontrastlÄ± fotoÄŸraflarÄ± CLAHE tekniÄŸi ile iyileÅŸtirir."""
    print("     -> Tarif uygulanÄ±yor: CLAHE ile Adaptif Kontrast...")
    # ... (kod aynÄ±)
    cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2LAB)
    l_channel, a_channel, b_channel = cv2.split(cv_image)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l_channel)
    merged_channels = cv2.merge([cl, a_channel, b_channel])
    final_cv_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2RGB)
    return Image.fromarray(final_cv_image)


def recipe_intelligent_crop(pil_image):
    """TARÄ°F 3 (YAPAY ZEKA DESTEKLÄ°): Kompozisyonu iyileÅŸtirmek iÃ§in akÄ±llÄ± kÄ±rpma (re-framing) yapar."""
    print("     -> Tarif uygulanÄ±yor: Kompozisyon iÃ§in AkÄ±llÄ± KÄ±rpma...")
    # ... (kod aynÄ±)
    cascade_path = 'haarcascade_frontalface_default.xml'
    if not os.path.exists(cascade_path):
        print(f"     âŒ HATA: '{cascade_path}' bulunamadÄ±. LÃ¼tfen indirip proje klasÃ¶rÃ¼ne koyun.")
        return pil_image
    face_cascade = cv2.CascadeClassifier(cascade_path)
    cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    gray_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray_image, 1.1, 4)
    if len(faces) == 0:
        print("     -> Bilgi: FotoÄŸrafta yÃ¼z tespit edilemedi. KÄ±rpma iÅŸlemi atlanÄ±yor.")
        return pil_image
    height, width = pil_image.size[1], pil_image.size[0]
    interest_center_x = int(np.mean([x + w / 2 for x, y, w, h in faces]))
    interest_center_y = int(np.mean([y + h / 2 for x, y, w, h in faces]))
    power_points = [(width // 3, height // 3), (2 * width // 3, height // 3), (width // 3, 2 * height // 3),
                    (2 * width // 3, 2 * height // 3)]
    closest_point = min(power_points, key=lambda p: (p[0] - interest_center_x) ** 2 + (p[1] - interest_center_y) ** 2)
    dx = closest_point[0] - interest_center_x
    dy = closest_point[1] - interest_center_y
    new_x1 = max(0, 0 + dx)
    new_y1 = max(0, 0 + dy)
    new_x2 = min(width, width + dx)
    new_y2 = min(height, height + dy)
    crop_width = new_x2 - new_x1
    crop_height = new_y2 - new_y1
    if crop_width / crop_height > width / height:
        new_y1 = int(new_y1 - ((crop_width * height / width) - crop_height) / 2)
        new_y2 = new_y1 + int(crop_width * height / width)
    else:
        new_x1 = int(new_x1 - ((crop_height * width / height) - crop_width) / 2)
        new_x2 = new_x1 + int(crop_height * width / height)
    final_x1, final_y1, final_x2, final_y2 = max(0, new_x1), max(0, new_y1), min(width, new_x2), min(height, new_y2)
    return pil_image.crop((final_x1, final_y1, final_x2, final_y2))


def recipe_shadow_recovery(pil_image):
    """TARÄ°F 4: FotoÄŸrafÄ±n karanlÄ±k bÃ¶lgelerindeki (gÃ¶lgelerdeki) detaylarÄ± ortaya Ã§Ä±karÄ±r."""
    print("     -> Tarif uygulanÄ±yor: GÃ¶lgeleri Kurtarma...")
    # ... (kod aynÄ±)
    cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    lab_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2LAB)
    l_channel, a_channel, b_channel = cv2.split(lab_image)
    gamma = 0.8
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    l_gamma_corrected = cv2.LUT(l_channel, table)
    merged_channels = cv2.merge([l_gamma_corrected, a_channel, b_channel])
    final_cv_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR)
    return Image.fromarray(cv2.cvtColor(final_cv_image, cv2.COLOR_BGR2RGB))


def recipe_vibrance_and_saturation(pil_image):
    """TARÄ°F 5 (HASSAS): Renkleri doÄŸal bir ÅŸekilde canlandÄ±rÄ±r."""
    print("     -> Tarif uygulanÄ±yor: Renk CanlÄ±lÄ±ÄŸÄ±nÄ± ArtÄ±rma...")
    converter = ImageEnhance.Color(pil_image)
    enhanced_image = converter.enhance(1.45) # Daha belirgin bir etki iÃ§in artÄ±rÄ±ldÄ±
    return enhanced_image


def recipe_unsharp_mask(pil_image):
    """TARÄ°F 6 (HASSAS): GÃ¶rseli "Unsharp Mask" ile akÄ±llÄ±ca keskinleÅŸtirir."""
    print("     -> Tarif uygulanÄ±yor: AkÄ±llÄ± KeskinleÅŸtirme (Unsharp Mask)...")
    return pil_image.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))


# --- "DANIÅMAN MODÃœLÃœ" (TÃ¼m DanÄ±ÅŸmanlar) ---

def analyze_exposure(pil_image):
    """DANIÅMAN 1: FotoÄŸrafÄ±n pozlamasÄ±nÄ± analiz eder."""
    cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2GRAY)
    mean_brightness = np.mean(cv_image)
    if mean_brightness < 70:
        return "DÃœÅÃœK POZLAMA", f"FotoÄŸraf Ã§ok karanlÄ±k (Ort. ParlaklÄ±k: {mean_brightness:.0f})."
    elif mean_brightness > 185:
        return "YÃœKSEK POZLAMA", f"FotoÄŸraf Ã§ok parlak (Ort. ParlaklÄ±k: {mean_brightness:.0f})."
    else:
        return "Ä°YÄ° POZLAMA", f"Pozlama dengeli (Ort. ParlaklÄ±k: {mean_brightness:.0f})."


def analyze_contrast_with_histogram(pil_image):
    """DANIÅMAN 2 (SAYISAL): Histogram analizi ile kontrastÄ± Ã¶lÃ§er."""
    cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2GRAY)
    hist = cv2.calcHist([cv_image], [0], None, [256], [0, 256])
    cdf = hist.cumsum()
    p5 = np.searchsorted(cdf, cdf[-1] * 0.05)
    p95 = np.searchsorted(cdf, cdf[-1] * 0.95)
    dynamic_range = p95 - p5
    if dynamic_range < 100:
        return "DÃœÅÃœK KONTRAST", f"Pikseller dar bir aralÄ±ÄŸa sÄ±kÄ±ÅŸmÄ±ÅŸ (Dinamik AralÄ±k: {dynamic_range}). FotoÄŸraf puslu/soluk."
    else:
        return "Ä°YÄ° KONTRAST", f"Kontrast seviyesi dengeli (Dinamik AralÄ±k: {dynamic_range})."


def analyze_rule_of_thirds(pil_image):
    """DANIÅMAN 3: Kompozisyonu, yÃ¼z tespiti yaparak analiz eder."""
    cascade_path = 'haarcascade_frontalface_default.xml'
    if not os.path.exists(cascade_path):
        return "ANALÄ°Z EDÄ°LEMEDÄ°", "Haar Cascade dosyasÄ± eksik."
    face_cascade = cv2.CascadeClassifier(cascade_path)
    gray_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray_image, 1.1, 4)
    if len(faces) == 0:
        return "BELÄ°RSÄ°Z", "Odak noktasÄ± (yÃ¼z) tespit edilemedi."
    height, width = pil_image.size[1], pil_image.size[0]
    interest_center_x = int(np.mean([x + w / 2 for x, y, w, h in faces]))
    interest_center_y = int(np.mean([y + h / 2 for x, y, w, h in faces]))
    center_threshold_x = width * 0.2
    center_threshold_y = height * 0.2
    if (width / 2 - center_threshold_x < interest_center_x < width / 2 + center_threshold_x) and \
            (height / 2 - center_threshold_y < interest_center_y < height / 2 + center_threshold_y):
        return "MERKEZÄ° KOMPOZÄ°SYON", "Ana obje (yÃ¼zler) kadrajÄ±n merkezinde."
    else:
        return "DENGELÄ° KOMPOZÄ°SYON", "Ana obje (yÃ¼zler) merkez dÄ±ÅŸÄ±nda."


def analyze_color_vibrance(pil_image):
    """DANIÅMAN 4 (HASSAS): Renklerin canlÄ±lÄ±ÄŸÄ±nÄ± (vibrance) analiz eder."""
    hsv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2HSV)
    saturation_channel = hsv_image[:, :, 1]
    mean_saturation = np.mean(saturation_channel)
    if mean_saturation < 80:
        return "DÃœÅÃœK CANLILIK", f"Renkler soluk gÃ¶rÃ¼nÃ¼yor (Ort. Doygunluk: {mean_saturation:.0f})."
    else:
        return "Ä°YÄ° CANLILIK", f"Renkler yeterince canlÄ± (Ort. Doygunluk: {mean_saturation:.0f})."


def analyze_sharpness(pil_image):
    """DANIÅMAN 5 (HASSAS): GÃ¶rselin netliÄŸini/keskinliÄŸini analiz eder."""
    cv_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2GRAY)
    variance = cv2.Laplacian(cv_image, cv2.CV_64F).var()
    if variance < 100:
        return "YUMUÅAK ODAK", f"GÃ¶rsel biraz yumuÅŸak (Netlik Skoru: {variance:.0f})."
    else:
        return "Ä°YÄ° KESKÄ°NLÄ°K", f"GÃ¶rsel yeterince keskin (Netlik Skoru: {variance:.0f})."


# --- Ã‡EKÄ°RDEK YARDIMCI FONKSÄ°YONLAR ---

def aspect_ratio_pad_resize(pil_image, target_size):
    """GÃ¶rselin en-boy oranÄ±nÄ± koruyarak hedef boyuta sÄ±ÄŸdÄ±rÄ±r ve dolgu ekler."""
    # ... (kod aynÄ±)
    original_width, original_height = pil_image.size
    target_width, target_height = target_size
    ratio = min(target_width / original_width, target_height / original_height)
    new_width = int(original_width * ratio)
    new_height = int(original_height * ratio)
    resized_img = pil_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
    delta_w, delta_h = target_width - new_width, target_height - new_height
    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))
    return ImageOps.expand(resized_img, padding, fill=(128, 128, 128))


def get_score_for_pil(pil_image, model_predictor):
    """Verilen bir PIL gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼, en-boy oranÄ±nÄ± koruyarak skorlar."""
    # ... (kod aynÄ±)
    processed_image = aspect_ratio_pad_resize(pil_image, MODEL_REQUIRED_SIZE)
    with io.BytesIO() as buffer:
        img_format = 'PNG' if pil_image.format in ['PNG', None] else 'JPEG'
        processed_image.save(buffer, format=img_format)
        image_bytes = buffer.getvalue()
    image_tensor = tf.constant(image_bytes, dtype=tf.string)
    inputs = {'image_bytes_tensor': image_tensor}
    try:
        score_tensor = model_predictor(**inputs)
        return score_tensor['output_0'].numpy()
    except Exception as e:
        print(f"âŒ Skorlama sÄ±rasÄ±nda hata: {e}")
        return 0.0


# --- AKILLI OPTÄ°MÄ°ZASYON MOTORU (GÃœNCELLENMÄ°Å EYLEM PLANI) ---

# --- AKILLI OPTÄ°MÄ°ZASYON MOTORU (GÃœNCELLENMÄ°Å EYLEM PLANI) ---

# --- AKILLI OPTÄ°MÄ°ZASYON MOTORU (GÃœNCELLENMÄ°Å EYLEM PLANI) ---

def optimize_for_score(original_pil_image, initial_score, model_predictor, analysis_report_statuses):
    """Tespit edilen temel ve hassas sorunlarÄ± Ã§Ã¶zmeye yÃ¶nelik tarifleri dener."""
    print("\n" + "=" * 50)
    print("ğŸ¤– AkÄ±llÄ± Optimizasyon Motoru BaÅŸlatÄ±lÄ±yor...")
    best_image, best_score, action_taken = original_pil_image, initial_score, False

    # Tariflerin sÄ±rasÄ± Ã¶nemli: Ã¶nce temel sorunlar, sonra hassas iyileÅŸtirmeler.
    # Kompozisyon en son olmalÄ±.
    potential_recipes = [
        # Temel Sorun Gidericiler
        ("YÃœSEK POZLAMA", "PatlamÄ±ÅŸ AlanlarÄ± Kurtarma", recipe_recover_highlights),
        ("DÃœÅÃœK KONTRAST", "CLAHE ile Adaptif Kontrast", recipe_clahe_contrast_enhancement),

        # Hassas Ä°yileÅŸtiriciler (Analiz raporunda tespit edilirse veya 'Ä°YÄ°' olsa bile denenmesi istenirse)
        # Bu kÄ±sÄ±mda "HER ZAMAN_" yerine daha spesifik koÅŸullar veya mantÄ±k kullanalÄ±m.
        ("DÃœÅÃœK CANLILIK", "Renk CanlÄ±lÄ±ÄŸÄ±nÄ± ArtÄ±rma", recipe_vibrance_and_saturation),  # Raporda DÃœÅÃœK CANLILIK varsa
        ("Ä°YÄ° CANLILIK_GELISTIR", "Renk CanlÄ±lÄ±ÄŸÄ±nÄ± ArtÄ±rma (Daha da)", recipe_vibrance_and_saturation),
        # Ä°YÄ° olsa bile geliÅŸtirilebilir olarak dene
        ("YUMUÅAK ODAK", "AkÄ±llÄ± KeskinleÅŸtirme", recipe_unsharp_mask),  # Raporda YUMUÅAK ODAK varsa
        ("Ä°YÄ° KESKÄ°NLIK_GELISTIR", "AkÄ±llÄ± KeskinleÅŸtirme (Daha da)", recipe_unsharp_mask),
        # Ä°YÄ° olsa bile geliÅŸtirilebilir olarak dene
        ("Ä°YÄ° POZLAMA_GOLGE", "GÃ¶lgeleri Kurtarma", recipe_shadow_recovery),  # Pozlama iyi olsa bile gÃ¶lgeleri kurtar
        ("DÃœÅÃœK POZLAMA_GOLGE", "GÃ¶lgeleri Kurtarma", recipe_shadow_recovery),
        # Pozlama dÃ¼ÅŸÃ¼kse de gÃ¶lgeleri kurtar (Ã¶ncelik ver)

        # Kompozisyon (En Son)
        ("MERKEZÄ° KOMPOZÄ°SYON", "Kompozisyon iÃ§in AkÄ±llÄ± KÄ±rpma", recipe_intelligent_crop),
    ]

    for condition, name, operation in potential_recipes:
        should_apply_recipe = False

        if condition in analysis_report_statuses:  # EÄŸer rapor direk bu condition'Ä± iÃ§eriyorsa
            should_apply_recipe = True
        elif condition == "Ä°YÄ° CANLILIK_GELISTIR" and "Ä°YÄ° CANLILIK" in analysis_report_statuses:
            should_apply_recipe = True
        elif condition == "Ä°YÄ° KESKÄ°NLIK_GELISTIR" and "Ä°YÄ° KESKÄ°NLÄ°K" in analysis_report_statuses:
            should_apply_recipe = True
        elif condition == "Ä°YÄ° POZLAMA_GOLGE" and "Ä°YÄ° POZLAMA" in analysis_report_statuses:
            should_apply_recipe = True
        elif condition == "DÃœÅÃœK POZLAMA_GOLGE" and "DÃœÅÃœK POZLAMA" in analysis_report_statuses:
            should_apply_recipe = True

        if should_apply_recipe:
            action_taken = True
            print(f"\n   - Durum: '{condition}'. Ã‡Ã¶zÃ¼m deneniyor: '{name}'...")

            candidate_image = operation(best_image)

            if name == "Kompozisyon iÃ§in AkÄ±llÄ± KÄ±rpma" and \
                    (
                            candidate_image.width < best_image.width * 0.7 or candidate_image.height < best_image.height * 0.7):
                print("     âŒ BaÅŸarÄ±sÄ±z. KÄ±rpma sonucu Ã§ok kÃ¼Ã§Ã¼k, deÄŸiÅŸiklik geri alÄ±nÄ±yor.")
                continue

            new_score = get_score_for_pil(candidate_image, model_predictor)
            if new_score > best_score:
                print(f"     âœ… BAÅARILI! Skor {best_score:.2f} -> {new_score:.2f}'a yÃ¼kseldi. Bu deÄŸiÅŸiklik kalÄ±cÄ±.")
                best_image, best_score = candidate_image, new_score
            else:
                print(f"     âŒ BaÅŸarÄ±sÄ±z. Skor dÃ¼ÅŸtÃ¼ veya aynÄ± kaldÄ± ({new_score:.2f}). DeÄŸiÅŸiklik geri alÄ±nÄ±yor.")

    if not action_taken and initial_score == best_score:
        print("   - Analiz raporunda eyleme geÃ§irilebilir bir sorun bulunamadÄ± ve hiÃ§bir tarif skoru artÄ±ramadÄ±.")

    print(f"\nâœ… Optimizasyon tamamlandÄ±. Nihai Skor: {best_score:.2f}")
    return best_image


# --- ANA UYGULAMA (GÃœNCELLENMÄ°Å RAPORLAMA) ---

def main():
    """UygulamanÄ±n ana akÄ±ÅŸÄ±nÄ± yÃ¶netir."""
    print("--- Aesthetic Enhancer AI (Hassas Ä°yileÅŸtirme SÃ¼rÃ¼mÃ¼) BaÅŸlatÄ±lÄ±yor ---")

    # AdÄ±m 1: Modeli yÃ¼kle
    print("\nğŸ§  MUSIQ Modeli yÃ¼kleniyor...")
    try:
        musiq_model = hub.load(MUSIQ_MODEL_URL)
        predictor = musiq_model.signatures["serving_default"]
        print("âœ… Model baÅŸarÄ±yla yÃ¼klendi.")
    except Exception as e:
        print(f"âŒ Model yÃ¼klenirken hata: {e}"); return

    # AdÄ±m 2: GÃ¶rseli yÃ¼kle ve baÅŸlangÄ±Ã§ skorunu al
    try:
        original_pil_image = Image.open(TEST_IMAGE_PATH)
        # OTOMATÄ°K ROTASYON DÃœZELTME
        original_pil_image = ImageOps.exif_transpose(original_pil_image).convert("RGB")
        print("âœ… GÃ¶rsel baÅŸarÄ±yla yÃ¼klendi ve EXIF rotasyonu dÃ¼zeltildi.")
        initial_score = get_score_for_pil(original_pil_image, predictor)
    except FileNotFoundError:
        print(f"âŒ HATA: '{TEST_IMAGE_PATH}' bulunamadÄ±."); return
    except Exception as e:
        print(f"âŒ GÃ¶rsel yÃ¼klenirken hata: {e}"); return

    print("\n" + "=" * 50)
    print(f"ğŸ–¼ï¸ Analiz Edilen GÃ¶rsel: {TEST_IMAGE_PATH}")
    print(f"âœ¨ BaÅŸlangÄ±Ã§ Estetik Skoru: {initial_score:.2f}")

    # AdÄ±m 3: AnlÄ±k Geri Bildirim Raporu OluÅŸtur (TÃ¼m Analizler)
    print("\n" + "-" * 50)
    print("ğŸ§ AnlÄ±k Geri Bildirim Raporu (SayÄ±sal ve Hassas Analiz):")
    analysis_report_statuses = []

    # Raporlama sÄ±rasÄ±nÄ± mantÄ±klÄ± hale getirelim
    status, suggestion = analyze_exposure(original_pil_image)
    print(f"   - Pozlama: {status} -> {suggestion}")
    analysis_report_statuses.append(status)

    status, suggestion = analyze_contrast_with_histogram(original_pil_image)
    print(f"   - Kontrast: {status} -> {suggestion}")
    analysis_report_statuses.append(status)

    status, suggestion = analyze_color_vibrance(original_pil_image)
    print(f"   - Renk CanlÄ±lÄ±ÄŸÄ±: {status} -> {suggestion}")
    analysis_report_statuses.append(status)

    status, suggestion = analyze_sharpness(original_pil_image)
    print(f"   - Netlik: {status} -> {suggestion}")
    analysis_report_statuses.append(status)

    status, suggestion = analyze_rule_of_thirds(original_pil_image)
    print(f"   - Kompozisyon: {status} -> {suggestion}")
    analysis_report_statuses.append(status)
    print("-" * 50)

    # AdÄ±m 4: AkÄ±llÄ± Optimizasyon Motorunu Ã‡alÄ±ÅŸtÄ±r
    enhanced_image = optimize_for_score(original_pil_image, initial_score, predictor, analysis_report_statuses)

    # AdÄ±m 5: Sonucu Kaydet
    if enhanced_image is not original_pil_image:
        save_path = "enhanced_" + os.path.basename(TEST_IMAGE_PATH)
        enhanced_image.save(save_path)
        print(f"\nğŸ’¾ Optimize edilmiÅŸ gÃ¶rsel '{save_path}' adÄ±yla kaydedildi.")
    else:
        print("\nğŸ’¾ GÃ¶rselde iyileÅŸtirme yapÄ±lmadÄ±ÄŸÄ± veya bulunmadÄ±ÄŸÄ± iÃ§in yeni dosya kaydedilmedi.")


if __name__ == "__main__":
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    main()